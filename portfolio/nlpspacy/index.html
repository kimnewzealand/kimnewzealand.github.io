<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Name Entity Recognition using Python spaCy in R</title>

<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="robots" content="all,follow">
<meta name="googlebot" content="index,follow,snippet,archive">
<link rel="stylesheet" href="/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/owl.carousel.css">
<link rel="stylesheet" href="/css/owl.theme.css">


  <link href="/css/style.style.sea.css.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="/img/favicon.png">


<script>
window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
ga('create', 'UA-114904130-1', 'auto');
ga('send', 'pageview');
</script>
<script async src='//www.google-analytics.com/analytics.js'></script>

</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content">
    <h1 class="sidebar-heading"><a href="/">Kim Fitter</a></h1>
    
      <p class="sidebar-p">Curious about Data Science tools, algorithms and all types of visualisations. Based in Auckland, New Zealand</p>
    
    <ul class="sidebar-menu">
      
      
        <li><a href="/">Home</a></li>
      
        <li><a href="/about/">About</a></li>
      
    </ul>
    <p class="social">
  
  
  
  <a href="https://twitter.com/kim_fitter" data-animate-hover="pulse" class="external twitter">
    <i class="fa fa-twitter"></i>
  </a>
  
  
  
  <a href="mailto:kim@validly.co" data-animate-hover="pulse" class="email">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  
  
  <a href="https://github.com/kimnewzealand" data-animate-hover="pulse">
    <i class="fa fa-github"></i>
  </a>
  
</p>


    <div class="copyright">
      <p class="credit">
        
          Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)
        
        | Template by <a href="https://bootstrapious.com/free-templates" class="external">Bootstrapious.com</a>

&amp; ported to Hugo by <a href="https://github.com/kishaningithub">Kishan B</a>

      </p>
    </div>
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost pull-left"> <i class="fa fa-align-left"> </i>Menu</button>
  <h1 class="small-navbar-heading"><a href="/">Kim Fitter</a></h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Name Entity Recognition using Python spaCy in R</h1>
         <p><em>23 May 2018</em></p>
<p>I have been learning Natural Language Processing (NLP). Although there are many NLP R packages, this field appears to extensively use Python packages so I started my NLP journey in Python with a <a href="https://github.com/kimnewzealand/NLPexampleprojects/blob/master/Basic%2BText%2BMining%2BNLP%2BABC%2Bexample.ipynb">Jupyter notebook</a>. The Python packages included are the research tool <a href="https://www.nltk.org/">NLTK</a>, <a href="https://radimrehurek.com/gensim/">gensim</a> then the more recent <a href="https://spacy.io/">spaCy</a>.</p>
<p>The purpose of this post is the next step in the journey to produce a pipeline for text mining and Named Entity Recognition (NER) with the Python spaCy NLP Toolkit, in R.</p>
<p>This is also made possible with the interface to Python, the reticulate R package, as an .</p>
<p>This will cover the following:</p>
<ul>
<li><a href="#python-initialisation">Python initialisation in R</a></li>
<li><a href="#load-data">Load the data</a></li>
<li><a href="#data-summary">Data Summaries</a></li>
<li><a href="#named-entity-recognition-using-cleannlp">Named entity recognition with spaCy</a></li>
</ul>
<p>This will not include advanced topic modeling and training annotation models in spaCy.</p>
<br>
<hr>
<div id="load-packages" class="section level2">
<h2>Load Packages</h2>
<pre class="r"><code>library(tidyverse)
# Packages for manipulating data
library(stringr)
library(lubridate)
# Packages for NLP
library(NLP)
# install.packages(&quot;openNLPmodels.en&quot;,repos = &quot;http://datacube.wu.ac.at/&quot;, type = &quot;source&quot;)
library(openNLP)
library(cleanNLP)
# cnlp_download_corenlp() # install the coreNLP Java back end &#39;CoreNLP&#39; &lt;http://stanfordnlp.github.io/CoreNLP/&gt;
# Packages for Python interface
# Packages for Python
library(reticulate)
use_virtualenv(&quot;r-reticulate&quot;)</code></pre>
</div>
<div id="python-initialisation" class="section level2">
<h2>Python Initialisation</h2>
<p>We have loaded the required R packages including the <a href="https://rstudio.github.io/reticulate/articles/introduction.html">reticulate</a> R package which provides an R interface to Python modules, classes, and functions.</p>
<p>As per the <a href="https://cran.r-project.org/web/packages/cleanNLP/cleanNLP.pdf">cleanNLP R package documentation</a>, we will load the <a href="https://spacy.io/">spaCy</a> Python NLP backend.</p>
<pre class="r"><code># First set the executable. Note this needs to be set before any initialising
use_python(&quot;C:/Users/HOME/Anaconda3/python.exe&quot;) 
# py_available(initialize = TRUE) # should give TRUE
# Check Python configuration
py_config()</code></pre>
<pre><code>## python:         C:/Users/HOME/Anaconda3/python.exe
## libpython:      C:/Users/HOME/Anaconda3/python36.dll
## pythonhome:     C:\Users\HOME\ANACON~1
## version:        3.6.3 |Anaconda, Inc.| (default, Oct 15 2017, 03:27:45) [MSC v.1900 64 bit (AMD64)]
## Architecture:   64bit
## numpy:          C:\Users\HOME\ANACON~1\lib\site-packages\numpy
## numpy_version:  1.13.3
## 
## python versions found: 
##  C:/Users/HOME/Anaconda3/python.exe
##  C:\Users\Home\AppData\Local\Programs\Python\Python36\python.exe
##  C:\Users\Home\AppData\Local\Programs\Python\Python36\\python.exe
##  C:\Users\Home\ANACON~1\python.exe</code></pre>
<pre class="r"><code># Initialise the spaCy backend
cnlp_init_spacy()</code></pre>
</div>
<div id="load-data" class="section level2">
<h2>Load Data</h2>
<p>The <a href="https://www.kaggle.com/therohk/million-headlines/data">A Million News Headlines dataset</a> is easy to load with the read_csv function from the <a href="https://cran.r-project.org/web/packages/readr/index.html">readr</a> R package.</p>
<blockquote>
<p>This contains data of news headlines published over a period of 15 years. From the reputable Australian news source ABC (Australian Broadcasting Corp.)</p>
</blockquote>
<p>These files have been downloaded into a local directory first to agree to the terms of use.</p>
</div>
<div id="data-summary" class="section level2">
<h2>Data Summary</h2>
<p>Letâ€™s take a look at the ABC headline data.</p>
<pre class="r"><code># Change the date to a date format
abc$publish_date &lt;- as.Date(as.character(abc$publish_date), format = &#39;%Y%m%d&#39;)
# Add new columns for the year, month and day using the lubridate R package
abc &lt;- abc %&gt;%  
      mutate(year = lubridate::year(abc$publish_date),
             month = lubridate::month(abc$publish_date),
             day = lubridate::day(abc$publish_date))
# Take a look at the first rows in the  dataset
head(abc)</code></pre>
<pre><code>## # A tibble: 6 x 5
##   publish_date headline_text                              year month   day
##   &lt;date&gt;       &lt;chr&gt;                                     &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
## 1 2003-02-19   aba decides against community broadcasti~  2003  2.00    19
## 2 2003-02-19   act fire witnesses must be aware of defa~  2003  2.00    19
## 3 2003-02-19   a g calls for infrastructure protection ~  2003  2.00    19
## 4 2003-02-19   air nz staff in aust strike for pay rise   2003  2.00    19
## 5 2003-02-19   air nz strike to affect australian trave~  2003  2.00    19
## 6 2003-02-19   ambitious olsson wins triple jump          2003  2.00    19</code></pre>
<pre><code>## # A tibble: 15 x 2
## # Groups:   year [15]
##     year     n
##    &lt;dbl&gt; &lt;int&gt;
##  1  2017 44182
##  2  2016 54615
##  3  2015 77941
##  4  2014 82330
##  5  2013 92337
##  6  2012 89109
##  7  2011 77829
##  8  2010 74948
##  9  2009 76454
## 10  2008 80015
## 11  2007 77192
## 12  2006 66912
## 13  2005 73124
## 14  2004 72674
## 15  2003 64003</code></pre>
<pre><code>## # A tibble: 12 x 3
## # Groups:   year, month [12]
##     year month     n
##    &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;
##  1  2017 12.0   3032
##  2  2017 11.0   3607
##  3  2017 10.0   3747
##  4  2017  9.00  3588
##  5  2017  8.00  3893
##  6  2017  7.00  3723
##  7  2017  6.00  3456
##  8  2017  5.00  3616
##  9  2017  4.00  3486
## 10  2017  3.00  4474
## 11  2017  2.00  3873
## 12  2017  1.00  3687</code></pre>
<p>Since this is a large dataset, we will use a subset of articles from January, 2017.</p>
</div>
<div id="named-entity-recognition-using-cleannlp" class="section level2">
<h2>Named Entity Recognition using CleanNLP</h2>
<p>Annote the string of text using the cnlp_annotate function from <a href="https://cran.r-project.org/web/packages/cleanNLP/index.html">CleanNLP</a>. This annotate function performs the word tokensiation and parts of speech tagging steps.</p>
<pre class="r"><code># Annotate the string tf by running the annotation engine over the corpus of text
anno &lt;- cnlp_annotate(tf)
# Summarise the tokens by parts of speech
cnlp_get_token(anno, include_root = FALSE) %&gt;%
  group_by(upos) %&gt;%
  summarize(posnum = n()) %&gt;%
  arrange(desc(posnum)) </code></pre>
<pre><code>## # A tibble: 15 x 2
##    upos  posnum
##    &lt;chr&gt;  &lt;int&gt;
##  1 NOUN   14026
##  2 VERB    5051
##  3 ADJ     3831
##  4 ADP     3491
##  5 PART     716
##  6 NUM      650
##  7 ADV      597
##  8 DET      509
##  9 CCONJ    231
## 10 PRON     223
## 11 PUNCT    146
## 12 PROPN     79
## 13 X         45
## 14 INTJ      17
## 15 SYM       13</code></pre>
<pre class="r"><code># Summarise the count of entities
cnlp_get_entity(anno) %&gt;%
  group_by(entity_type) %&gt;%
  summarize(count = n())  %&gt;%
  arrange(desc(count)) </code></pre>
<pre><code>## # A tibble: 13 x 2
##    entity_type count
##    &lt;chr&gt;       &lt;int&gt;
##  1 DATE          340
##  2 CARDINAL      330
##  3 ORDINAL       133
##  4 NORP           40
##  5 GPE            38
##  6 TIME           28
##  7 MONEY          17
##  8 QUANTITY       11
##  9 PERSON          4
## 10 ORG             2
## 11 EVENT           1
## 12 LOC             1
## 13 PRODUCT         1</code></pre>
<pre class="r"><code># Extract the entities of type GPE which is are geo-political entities such as city, state/province, and country
cnlp_get_entity(anno) %&gt;%
  filter(entity_type == &quot;GPE&quot;) %&gt;%
  group_by(entity) %&gt;%
  summarize(count = n()) %&gt;%
  arrange(desc(count)) </code></pre>
<pre><code>## # A tibble: 6 x 2
##   entity  count
##   &lt;chr&gt;   &lt;int&gt;
## 1 india      15
## 2 china      11
## 3 japan       7
## 4 mexico      3
## 5 chicago     1
## 6 london      1</code></pre>
<pre class="r"><code># Extract the entities of type NORP which are Nationalities or religious or political groups.
cnlp_get_entity(anno) %&gt;%
  filter(entity_type == &quot;NORP&quot;) %&gt;%
  group_by(entity) %&gt;%
  summarize(count = n()) %&gt;%
  arrange(desc(count))</code></pre>
<pre><code>## # A tibble: 15 x 2
##    entity      count
##    &lt;chr&gt;       &lt;int&gt;
##  1 chinese        15
##  2 japanese        4
##  3 russian         4
##  4 american        3
##  5 british         2
##  6 european        2
##  7 mexico          2
##  8 173yo           1
##  9 190117          1
## 10 canadian        1
## 11 christian       1
## 12 israeli         1
## 13 korean          1
## 14 palestinian     1
## 15 republican      1</code></pre>
<pre class="r"><code># Extract the entities of type PERSON which are People, including fictional.
cnlp_get_entity(anno) %&gt;%
  filter(entity_type == &quot;PERSON&quot;) %&gt;%
  group_by(entity) %&gt;%
  summarize(count = n()) %&gt;%
  arrange(desc(count))</code></pre>
<pre><code>## # A tibble: 2 x 2
##   entity    count
##   &lt;chr&gt;     &lt;int&gt;
## 1 elizabeth     2
## 2 jack          2</code></pre>
<pre class="r"><code># Extract the entities of type ORG which are Companies, agencies, institutions, etc.
cnlp_get_entity(anno) %&gt;%
  filter(entity_type == &quot;ORG&quot;) %&gt;%
  group_by(entity) %&gt;%
  summarize(count = n()) %&gt;%
  arrange(desc(count))</code></pre>
<pre><code>## # A tibble: 2 x 2
##   entity count
##   &lt;chr&gt;  &lt;int&gt;
## 1 7 134      1
## 2 mafia      1</code></pre>
<pre class="r"><code># Extract the entities of type MONEY which are Monetary values, including unit.
cnlp_get_entity(anno) %&gt;%
  filter(entity_type == &quot;MONEY&quot;) %&gt;%
  group_by(entity) %&gt;%
  summarize(count = n()) %&gt;%
  arrange(desc(count))</code></pre>
<pre><code>## # A tibble: 17 x 2
##    entity              count
##    &lt;chr&gt;               &lt;int&gt;
##  1 $20m                    1
##  2 $493 billion            1
##  3 $6 million              1
##  4 $60 million             1
##  5 $6m                     1
##  6 15000                   1
##  7 20 cents                1
##  8 3 million dollars       1
##  9 5.8 per cent            1
## 10 50 per cent             1
## 11 500000                  1
## 12 70                      1
## 13 76                      1
## 14 8 mark                  1
## 15 more than $860000       1
## 16 more than 4 billion     1
## 17 over $60m               1</code></pre>
<p>The other entities types can be viewed in the spaCy <a href="https://spacy.io/usage/linguistic-features#section-named-entities">documentation</a>.</p>
<p>See the <a href="https://github.com/kimnewzealand/NLPexampleprojects">GitHub NLPexamples repo</a> for my other NLP projects in R and Python.</p>
</div>

         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="/js/jquery.min.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/jquery.cookie.js"> </script>
<script src="/js/ekko-lightbox.js"></script>
<script src="/js/jquery.scrollTo.min.js"></script>
<script src="/js/masonry.pkgd.min.js"></script>
<script src="/js/imagesloaded.pkgd.min.js"></script>
<script src="/js/owl.carousel.min.js"></script>
<script src="/js/front.js"></script>

</body>
</html>
