<!DOCTYPE html>
<html lang="en">

<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="generator" content="Hugo 0.31.1" />

  <title>Credit Risk Modeling and Scorecard Example &middot; Kim Fitter</title>

  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/pure-min.css">

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-old-ie-min.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pure/1.0.0/grids-responsive-min.css">
  <!--<![endif]-->

  <!--[if lte IE 8]>
  <link rel="stylesheet" href="https://kimnewzealand.github.io/css/side-menu-old-ie.css">
  <![endif]-->
  <!--[if gt IE 8]><!-->
  <link rel="stylesheet" href="https://kimnewzealand.github.io/css/side-menu.css">
  <!--<![endif]-->

  <link rel="stylesheet" href="https://kimnewzealand.github.io/css/blackburn.css">

  
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">

  
  <link href="https://fonts.googleapis.com/css?family=Raleway" rel="stylesheet" type="text/css">

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

 
  

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/androidstudio.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  
  <script>hljs.initHighlightingOnLoad();</script>
  

  <link rel="shortcut icon" href="https://kimnewzealand.github.io/img/favicon.ico" type="image/x-icon" />

  
  

</head>


<body>
<div id="layout">

  
<a href="#menu" id="menuLink" class="menu-link">
  
  <span></span>
</a>
<div id="menu">

  
  <a class="pure-menu-heading brand" href="https://kimnewzealand.github.io/">Kim Fitter</a>


  <div class="pure-menu">
    <ul class="pure-menu-list">
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://kimnewzealand.github.io/"><i class='fa fa-home fa-fw'></i>Home</a>
      
        </li>
      
      
        <li class="pure-menu-item">
          <a class="pure-menu-link" href="https://kimnewzealand.github.io/about/"><i class='fa fa-user fa-fw'></i>About</a>
      
        </li>
      
    </ul>
  </div>

  <div class="pure-menu social">
  <ul class="pure-menu-list">



    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://twitter.com/kim_fitter" target="_blank"><i class="fa fa-twitter-square fa-fw"></i>Twitter</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    

    
    <li class="pure-menu-item">
      <a class="pure-menu-link" href="https://github.com/kimnewzealand" target="_blank"><i class="fa fa-github-square fa-fw"></i>GitHub</a>
    </li>
    

    

    

    

    

    

    

    

    

    

    

    

    

  </ul>
</div>


  <div>
  <div class="small-print">
    <small>Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0)</small>
  </div>
  <div class="small-print">
    <small>Built with&nbsp;<a href="https://gohugo.io/" target="_blank">Hugo</a></small>
    <small>Theme&nbsp;<a href="https://github.com/yoshiharuyamashita/blackburn" target="_blank">Blackburn</a></small>
  </div>
</div>

</div>


  <div id="main">


<div class="header">
  <h1>Credit Risk Modeling and Scorecard Example</h1>
  <h2></h2>
</div>
<div class="content">

  <div class="post-meta">

  <div>
    <i class="fa fa-calendar fa-fw"></i>
    <time>15 Aug 2018</time>
  </div>

  

  

  
  
  
  <div>
    <i class="fa fa-tags fa-fw"></i>
    
      <a class="post-taxonomy-tag" href="https://kimnewzealand.github.io/tags/r">R</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://kimnewzealand.github.io/tags/modeling">modeling</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://kimnewzealand.github.io/tags/creditrisk">creditrisk</a>&nbsp;&#47;
    
      <a class="post-taxonomy-tag" href="https://kimnewzealand.github.io/tags/eda">EDA</a>
    
  </div>
  
  

</div>

  <ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#load-data">Load the data</a></li>
<li><a href="#summary-of-data">Summary of data</a></li>
<li><a href="#clean-data">Clean Data</a></li>
<li><a href="#exploratory-data-analysis">Exploratory Data Analysis</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#training">Training</a></li>
<li><a href="#create-scorecard">Create Scorecard</a></li>
<li><a href="#conclusions">Conclusions</a></li>
</ul>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Credit Risk modeling predicts whether a customer or applicant may or may not default on a loan. These models include predictor variables that are categorical or numeric. One of the outputs in the modeling process is a credit scorecard with attributes to allocate scores.</p>
<p>The objectives of this post are as follow:</p>
<ul>
<li>Create models using logistic regression</li>
<li>Compare manual coarse binning with automated optimal Weight-of-Evidence (WOE) and Information Value (IV) binning</li>
<li>Understand the WOE calculations</li>
<li>Create a credit scorecard</li>
</ul>
<p>Here we will use a public dataset, German Credit Data, with a binary response variable, good or bad risk. We will evaluate and compare the models with typical credit risk model measures, AUC and <a href="https://www.itl.nist.gov/div898/handbook/eda/section3/eda35g.htm">Kolmogorov-Smirnov test (KS)</a>.</p>
<pre class="r"><code>library(tidyverse)
# Packages for loading data
library(httr)
# Packages for data manipulation
library(purrr)
# Packages for visualisation
library(Information)
library(gmodels)
library(DataExplorer)
# Packages for modeling
library(pROC)
library(scorecard)</code></pre>
</div>
<div id="load-data" class="section level2">
<h2>Load data</h2>
<p>Load the <a href="https://archive.ics.uci.edu/ml/support/statlog+(german+credit+data)">Statlog (German Credit Data) Data Set</a> with <a href="https://cran.r-project.org/web/packages/httr/index.html">httr</a> and <a href="https://cran.r-project.org/web/packages/readr/index.html">readr</a> R packages. Note readr is available from <a href="http://r-pkgs.had.co.nz/namespace.html#search-path">loading and attaching the package to the search path</a> with library(tidyverse) above.</p>
<pre class="r"><code># Set the url and uset GET function from httr to import the csv file to a temporary local directory, and read_csv from readr R package. This csv is also available at this url, with variable names. The UCI link does not include variable names and this will save us a step.
url &lt;- (&quot;http://www.biz.uiowa.edu/faculty/jledolter/DataMining/germancredit.csv&quot;)
GET(url, write_disk(tf &lt;- tempfile(fileext = &quot;.data&quot;)))</code></pre>
<pre><code>## Response [https://www.biz.uiowa.edu/faculty/jledolter/DataMining/germancredit.csv]
##   Date: 2018-09-03 22:10
##   Status: 200
##   Content-Type: text/csv
##   Size: 81 kB
## &lt;ON DISK&gt;  C:\Users\Home\AppData\Local\Temp\RtmpEREOML\file16080716649d9.data</code></pre>
<pre class="r"><code>creditdata &lt;- read_csv(tf)</code></pre>
<pre><code>## Parsed with column specification:
## cols(
##   .default = col_character(),
##   Default = col_integer(),
##   duration = col_integer(),
##   amount = col_integer(),
##   installment = col_integer(),
##   residence = col_integer(),
##   age = col_integer(),
##   cards = col_integer(),
##   liable = col_integer()
## )</code></pre>
<pre><code>## See spec(...) for full column specifications.</code></pre>
</div>
<div id="summary-of-data" class="section level2">
<h2>Summary of data</h2>
<p>The dataset <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">metadata</a> describes this data. This dataset appears to represent approved loan data, and would therefore exclude rejected applications.</p>
<p>Letâ€™s first take a look at a summary using skim function from the <a href="https://cran.r-project.org/web/packages/skimr/index.html">skimr</a> package.</p>
<pre class="r"><code># Plot the summary excluding the histograms as these do not print in R Markdown html yet
skimr::skim_with(integer = list(hist = NULL))
skimr::skim(creditdata)</code></pre>
<pre><code>## Skim summary statistics
##  n obs: 1000 
##  n variables: 21 
## 
## -- Variable type:character ----------------------------------------------------------------------
##         variable missing complete    n min max empty n_unique
##  checkingstatus1       0     1000 1000   3   3     0        4
##           employ       0     1000 1000   3   3     0        5
##          foreign       0     1000 1000   4   4     0        2
##          history       0     1000 1000   3   3     0        5
##          housing       0     1000 1000   4   4     0        3
##              job       0     1000 1000   4   4     0        4
##       otherplans       0     1000 1000   4   4     0        3
##           others       0     1000 1000   4   4     0        3
##         property       0     1000 1000   4   4     0        4
##          purpose       0     1000 1000   3   4     0       10
##          savings       0     1000 1000   3   3     0        5
##           status       0     1000 1000   3   3     0        4
##             tele       0     1000 1000   4   4     0        2
## 
## -- Variable type:integer ------------------------------------------------------------------------
##     variable missing complete    n    mean      sd  p0    p25    p50
##          age       0     1000 1000   35.55   11.38  19   27     33  
##       amount       0     1000 1000 3271.26 2822.74 250 1365.5 2319.5
##        cards       0     1000 1000    1.41    0.58   1    1      1  
##      Default       0     1000 1000    0.3     0.46   0    0      0  
##     duration       0     1000 1000   20.9    12.06   4   12     18  
##  installment       0     1000 1000    2.97    1.12   1    2      3  
##       liable       0     1000 1000    1.16    0.36   1    1      1  
##    residence       0     1000 1000    2.85    1.1    1    2      3  
##      p75  p100
##    42       75
##  3972.25 18424
##     2        4
##     1        1
##    24       72
##     4        4
##     1        2
##     4        4</code></pre>
</div>
<div id="clean-data" class="section level2">
<h2>Clean Data</h2>
<p>Next we will clean the dataset using <a href="https://cran.r-project.org/web/packages/dplyr/index.html">dplyr</a> and <a href="https://cran.r-project.org/web/packages/purrr/index.html">purrr</a> R packages.</p>
<p>From the <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">metadata</a>, the following variables are numeric:</p>
<ul>
<li>Attribute 2: duration (numerical) Duration in month<br />
</li>
<li>Attribute 5: amount (numerical) Credit amount<br />
</li>
<li>Attribute 8: instalment (numerical) Instalment rate in percentage of disposable income<br />
</li>
<li>Attribute 11: residence (numerical) Present residence since<br />
</li>
<li>Attribute 13: age (numerical) Age in years</li>
<li>Attribute 18: liable (numerical) Number of people being liable to provide maintenance for</li>
</ul>
<pre class="r"><code>head(creditdata)</code></pre>
<pre><code>## # A tibble: 6 x 21
##   Default checkingstatus1 duration history purpose amount savings employ
##     &lt;int&gt; &lt;chr&gt;              &lt;int&gt; &lt;chr&gt;   &lt;chr&gt;    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; 
## 1       0 A11                    6 A34     A43       1169 A65     A75   
## 2       1 A12                   48 A32     A43       5951 A61     A73   
## 3       0 A14                   12 A34     A46       2096 A61     A74   
## 4       0 A11                   42 A32     A42       7882 A61     A74   
## 5       1 A11                   24 A33     A40       4870 A61     A73   
## 6       0 A14                   36 A32     A46       9055 A65     A73   
## # ... with 13 more variables: installment &lt;int&gt;, status &lt;chr&gt;,
## #   others &lt;chr&gt;, residence &lt;int&gt;, property &lt;chr&gt;, age &lt;int&gt;,
## #   otherplans &lt;chr&gt;, housing &lt;chr&gt;, cards &lt;int&gt;, job &lt;chr&gt;, liable &lt;int&gt;,
## #   tele &lt;chr&gt;, foreign &lt;chr&gt;</code></pre>
<p>However from the view of the first rows, instalment, residence and duration appear to be categorical variables, as they are classification groupings. Therefore we will only convert duration, amount and age to numeric variables.</p>
<pre class="r"><code># Change the numerical variables to numeric using map_at function from purrr R package
creditdata &lt;- creditdata %&gt;% 
      mutate_at(vars(duration,amount,age),as.numeric) %&gt;% 
      data.frame(stringsAsFactors = FALSE)

# Convert remaining integer variables to character ie categorical variables using map_if function from purrr R package
creditdata &lt;- creditdata %&gt;% 
      map_if(is.integer,as.character) %&gt;% 
      data.frame() # leave as factors with default argument

# Rename the default variable to lower case for naming consistency
names(creditdata) &lt;- tolower(names(creditdata))

# Convert the default variable to numeric and binary for modeling
creditdata$default &lt;- as.numeric(creditdata$default)
creditdata$default &lt;- recode(creditdata$default,&#39;1&#39;=0L,&#39;2&#39;=1L)</code></pre>
<p>Next recode the variable levels with the <a href="https://cran.r-project.org/web/packages/forcats/index.html">forcats</a> R package so that the variables are easier to understand in the plots. We have recoded as per the <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">metadata</a>.</p>
<pre class="r"><code># Recode with fct_recode function
creditdata$checkingstatus1 &lt;- fct_recode(creditdata$checkingstatus1, less0=&#39;A11&#39;, low0to200DM=&#39;A12&#39;, highover200DM=&#39;A13&#39;, noaccount=&#39;A14&#39;)
creditdata$history &lt;- fct_recode(creditdata$history, nocredit=&#39;A30&#39;, creditpaid=&#39;A31&#39;,creditpaidtilnow =&#39;A32&#39;, pastdelays=&#39;A33&#39;,otherbankcredit=&#39;A34&#39;)
creditdata$purpose &lt;- fct_recode(creditdata$purpose, car_new=&#39;A40&#39;, car_used=&#39;A41&#39;,furniture =&#39;A42&#39;, radio_tv=&#39;A43&#39;,appliance=&#39;A44&#39;, repairs=&#39;A45&#39;, education=&#39;A46&#39;,  retraining=&#39;A48&#39;, business=&#39;A49&#39;, others=&#39;A410&#39;) #vacation=&#39;A47&#39;does not exist in data
creditdata$others &lt;- fct_recode(creditdata$others, noguarantors=&#39;A101&#39;, coapplicant=&#39;A102&#39;,guarantor =&#39;A103&#39;)
creditdata$property &lt;- fct_recode(creditdata$property, realestate=&#39;A121&#39;, othersavings=&#39;A122&#39;,othercar =&#39;A123&#39;,noproperty=&#39;A124&#39;)
creditdata$otherplans &lt;- fct_recode(creditdata$otherplans, bankplans=&#39;A141&#39;, storeplans=&#39;A142&#39;,noplans =&#39;A143&#39;)
creditdata$status &lt;- fct_recode(creditdata$status, male_other=&#39;A91&#39;,female_other=&#39;A92&#39;, male_single=&#39;A93&#39;, male_other=&#39;A94&#39;, female_single=&#39;A95&#39;)</code></pre>
<pre><code>## Warning: Unknown levels in `f`: A95</code></pre>
<pre class="r"><code>creditdata$savings &lt;- fct_recode(creditdata$savings, less100DM=&#39;A61&#39;,f100to500DM=&#39;A62&#39;,f500to1000DM=&#39;A63&#39;,greater1000DM=&#39;A64&#39;,unknown=&#39;A65&#39;)
creditdata$employ &lt;- fct_recode(creditdata$employ, unemployed=&#39;A71&#39;,less1year=&#39;A72&#39;,f1to4years=&#39;A73&#39;,f4to7years=&#39;A74&#39;,over7years=&#39;A75&#39;)
creditdata$job &lt;- fct_recode(creditdata$job, unemployed=&#39;A171&#39;,unskilled=&#39;A172&#39;,skilled=&#39;A173&#39;,management=&#39;A174&#39;)
creditdata$foreign &lt;- fct_recode(creditdata$foreign, yes=&#39;A201&#39;,no=&#39;A202&#39;)
creditdata$housing &lt;- fct_recode(creditdata$housing, rent=&#39;A151&#39;,own=&#39;A152&#39;,free=&#39;A153&#39;)
creditdata$tele &lt;- fct_recode(creditdata$tele, none=&#39;A191&#39;,yes=&#39;A192&#39;)</code></pre>
<p>We note an warning message with the Unknown levels in â€˜fâ€™ :A95 in the <code>status</code> variable. It appears that there are no values for â€˜fâ€™.</p>
<p><strong>MISSING VALUES</strong></p>
<p>As per the <a href="https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)">metadata</a>, there are no missing values. Letâ€™s confirm with a missing values plot, plot_missing from Data Explorer package.</p>
<p>The <a href="https://cran.r-project.org/web/packages/DataExplorer/index.html">DataExplorer</a> speeds up data exploration process and automatically scans through each variable and does data profiling.</p>
<pre class="r"><code>plot_missing(creditdata)</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/missing%20plot-1.png" width="672" /></p>
<pre class="r"><code># Create a base dataset copy for the woe models
creditdata_base &lt;- creditdata</code></pre>
<p>With real data, we would also verify missing values coded other than NA.</p>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<div id="target-variable" class="section level3">
<h3>Target variable</h3>
<p>The response variable is <code>default</code> (As per the metadata 1 = Good, 2 = Bad) however the variable has been coded to 0 = Good and 1 = Bad in the dataset.</p>
<p>Letâ€™s take a look at the proportions of <code>default</code> and the <code>checkingstatus1</code> using the <a href="https://cran.r-project.org/web/packages/gmodels/index.html">gmodels</a> R package. We will use the <code>checkingstatus1</code> variable as an example to understand the WOE calculations.</p>
<pre class="r"><code># Use the CrossTable function from gmodels package on default and checkingstatus1 
gmodels::CrossTable(creditdata$default,
                    creditdata$checkingstatus1,prop.r= FALSE, prop.c =FALSE, prop.t=FALSE, chisq = TRUE)</code></pre>
<pre><code>## 
##  
##    Cell Contents
## |-------------------------|
## |                       N |
## | Chi-square contribution |
## |-------------------------|
## 
##  
## Total Observations in Table:  1000 
## 
##  
##                    | creditdata$checkingstatus1 
## creditdata$default |         less0 |   low0to200DM | highover200DM |     noaccount |     Row Total | 
## -------------------|---------------|---------------|---------------|---------------|---------------|
##                  0 |           139 |           164 |            49 |           348 |           700 | 
##                    |        14.535 |         3.136 |         0.544 |        18.901 |               | 
## -------------------|---------------|---------------|---------------|---------------|---------------|
##                  1 |           135 |           105 |            14 |            46 |           300 | 
##                    |        33.915 |         7.317 |         1.270 |        44.102 |               | 
## -------------------|---------------|---------------|---------------|---------------|---------------|
##       Column Total |           274 |           269 |            63 |           394 |          1000 | 
## -------------------|---------------|---------------|---------------|---------------|---------------|
## 
##  
## Statistics for All Table Factors
## 
## 
## Pearson&#39;s Chi-squared test 
## ------------------------------------------------------------
## Chi^2 =  123.7209     d.f. =  3     p =  1.218902e-26 
## 
## 
## </code></pre>
<p>From the table, 30% of the loans had a bad outcome in this dataset. If this was representative of the population then 30% of applicants cannot repay their loans. Given the Chi-squared test, we can reject a null hypothesis that these two variables, <code>default</code> and <code>checkingstatus1</code>, are independent. There appears to be some relationship between these two variables.</p>
<p>The imbalance in the dataset is worth noting, however real life datasets are typically highly imbalanced.</p>
</div>
<div id="categorical-variables" class="section level3">
<h3>Categorical Variables</h3>
<p>To visualize distributions for the categorical features, letâ€™s view frequency bar charts using DataExplorer.</p>
<pre class="r"><code># Barplot of categorical features using DataExplorer.
creditdata %&gt;%
      plot_bar()</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/barplot-1.png" width="672" /><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/barplot-2.png" width="672" /></p>
<p>From these barplots it appears that the majority of the loans are made by single males, however there is no data for single females. Most loans are used for purchasing a radio/ television, then new cars and majority of borrowers have low savings or no account with this bank. The borrowers are mostly foreign, skilled workers with existing property.</p>
</div>
<div id="numeric-variables" class="section level3">
<h3>Numeric Variables</h3>
<p>Now letâ€™s take a look at the <code>default</code> variable against the numeric variables as density plots.</p>
<pre class="r"><code># Use keep function from purrr, where columns are numeric ie TRUE are kept for our plots, then use purrr map function to plot a density plot for each numeric variable by default value
creditdata %&gt;%
      select(age,duration,amount) %&gt;% 
      map(~ggplot(creditdata, aes(x = .)) +
                geom_density(aes(fill=as.factor(default)),alpha=0.3) +
                scale_fill_viridis_d()) # New ggplot v3.0.0 includes viridis palette</code></pre>
<pre><code>## $age</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/density%20plots-1.png" width="672" /></p>
<pre><code>## 
## $duration</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/density%20plots-2.png" width="672" /></p>
<pre><code>## 
## $amount</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/density%20plots-3.png" width="672" /></p>
<p>From these density plots there do not appear to be outliers.</p>
<p>The <code>duration</code>, <code>amount</code> and <code>age</code> distributions and peaks appear to be different between <code>default</code> values, therefore these could be a predictor variable where higher duration is riskier, higher amount is riskier and lower age is riskier.</p>
</div>
<div id="feature-engineering" class="section level3">
<h3>Feature Engineering</h3>
<p>Before we fit models we will subjectively group the continuous numeric variables to binned categorical variables based on visualising cut-off points in the EDA above. This is called coarse binning as we will group values with similar risk, in as few bins as possible. With the new group variables, we will remove the original continuous variables.</p>
<pre class="r"><code># Create a new age_group variable, with buckets based on the density distribution above
creditdata &lt;- creditdata %&gt;% 
  mutate(age_group=factor(case_when(
  .$age &lt;  25 ~ &quot;25less&quot;,
  .$age &gt;= 25 &amp; .$age &lt;= 29 ~ &quot;25to29&quot;,
  .$age &gt;= 30 &amp; .$age &lt;= 39 ~ &quot;30to39&quot;,
  .$age &gt;= 40 &amp; .$age &lt;= 49 ~ &quot;40to49&quot;,
  .$age &gt;= 50 &amp; .$age &lt;= 59 ~ &quot;50to59&quot;,
  .$age &gt;= 60 &amp; .$age &lt;= 70 ~ &quot;60over&quot;,
  .$age &gt;= 70 ~ &quot;6&quot;)))
# Remove the original age variable to avoid feature interactions
creditdata &lt;- creditdata %&gt;% 
      dplyr::select(-age)</code></pre>
<pre class="r"><code># Create a new amount_group variable, with buckets based on the density distribution above
creditdata &lt;- creditdata %&gt;% 
  mutate(amount_group=factor(case_when(
  .$amount &lt;  1250 ~ &quot;1250less&quot;,
  .$amount &gt;= 1250 &amp; .$amount &lt;= 5000 ~ &quot;1250to5000&quot;,
  .$amount &gt;= 5000  ~ &quot;5000over&quot;)))
# Remove the original amount variable to avoid feature interactions
creditdata &lt;- creditdata %&gt;% 
      dplyr::select(-amount)</code></pre>
<pre class="r"><code># Create a new  duration_group variable, with buckets based on the density distribution above. We will group the months into years, we see peaks at the incremental 12 month marks
creditdata &lt;- creditdata %&gt;% 
  mutate(duration_group=factor(case_when(
  .$ duration &lt;  12 ~ &quot;1yearunder&quot;,
  .$ duration &gt;= 12 &amp; .$ duration &lt;= 24 ~ &quot;1to2year&quot;,
  .$ duration &gt;= 24 &amp; .$ duration &lt;= 36 ~ &quot;2to3year&quot;,
  .$ duration &gt;= 36 &amp; .$ duration &lt;= 48 ~ &quot;3to4year&quot;,
  .$ duration &gt;= 48  ~ &quot;4yearover&quot;)))
# Remove the original  duration variable to avoid feature interactions
creditdata &lt;- creditdata %&gt;% 
      dplyr::select(- duration)</code></pre>
</div>
</div>
<div id="training" class="section level2">
<h2>Training</h2>
<p>Split the data into training and test sets following the Data Camp course steps in <a href="https://campus.datacamp.com/courses/introduction-to-credit-risk-modeling-in-r/chapter-1-introduction-and-data-preprocessing?ex=12">Chapter 1</a>. Here we will use a 70:30 split between training and test sets and create splits for the base dataset for WOE binning and one which will be feature engineered with coarse binning.</p>
<pre class="r"><code># Set seed of 123 for reproduceability
set.seed(123)
# Store row numbers for training set: index_train using randomly assigned observations
index_train &lt;- sample(1:nrow(creditdata), 0.7 * nrow(creditdata))
# Create training set: training with the index
training &lt;- creditdata[index_train, ]
# Create test set: test with the index
test &lt;- creditdata[-index_train, ]

# Store row numbers for training set: index_train using randomly assigned observations
index_train_base &lt;- sample(1:nrow(creditdata_base), 0.7 * nrow(creditdata_base))
# Create training set: training with the index
training_base &lt;- creditdata_base[index_train_base, ]
# Create test set: test with the index
test_base &lt;- creditdata_base[-index_train_base, ]</code></pre>
<div id="model-1---logistic-model-with-coarse-binning" class="section level3">
<h3>Model 1 - Logistic Model with Coarse Binning</h3>
<p>Fit the first logistic model on the training data set where the variables have been coarse binned manually.</p>
<pre class="r"><code># Fit a logistic model using the base glm function
glm_model &lt;- glm(default ~ ., family = &quot;binomial&quot;, data= training)</code></pre>
<p>Make predictions on the test set and evaluate the model using AUC and K-S measures with the <a href="https://cran.r-project.org/web/packages/pROC/index.html">pROC</a>, <a href="https://cran.r-project.org/web/packages/ROCR/index.html">ROCR</a> and <a href="https://cran.r-project.org/web/packages/scorecard/index.html">scoredcard</a> R packages.</p>
<pre class="r"><code>prediction_prob &lt;- predict(glm_model, newdata = test, type = &quot;response&quot;)
ROC &lt;- pROC::roc(test$default,prediction_prob)
# AUC for the logistic model
AUC &lt;- pROC::auc(ROC )
AUC</code></pre>
<pre><code>## Area under the curve: 0.7804</code></pre>
<pre class="r"><code># KS for logistic
pred &lt;- ROCR::prediction(prediction_prob,test$default)
perf &lt;- ROCR::performance(pred,&quot;tpr&quot;,&quot;fpr&quot;)
KS &lt;- max(attr(perf,&#39;y.values&#39;)[[1]]-attr(perf,&#39;x.values&#39;)[[1]])
KS</code></pre>
<pre><code>## [1] 0.4548609</code></pre>
<p>Now use the the <a href="https://cran.r-project.org/web/packages/scorecard/index.html">scorecard</a> R package to plot the KS and AUC values.</p>
<pre class="r"><code># performance
test_perf &lt;- scorecard::perf_eva(test$default, prediction_prob, title = &quot;Model 1&quot;)</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/perf%20plots-1.png" width="672" /></p>
</div>
<div id="model-2---logistic-model-with-woe-binning" class="section level3">
<h3>Model 2 - Logistic Model with WOE Binning</h3>
<div id="information-theory-woe-and-iv" class="section level4">
<h4>Information Theory (WoE and IV)</h4>
<p>We can use the <a href="https://cran.r-project.org/web/packages/Information/index.html">Information</a> R package to perform variable screening using weight-of-evidence (WOE) and information value (IV).</p>
<blockquote>
<p>WOE and IV play two distinct roles when analyzing data:<br />
- WOE describes the relationship between a predictive variable and a binary target variable.<br />
- IV measures the strength of that relationship.</p>
</blockquote>
<p>The WOE framework optimises the number of bins and cut off points based on a risk value. If the variable is numeric then the cut off will respect the ordering, but it may not respect the ordering of the categorical values.</p>
<p>Letâ€™s view a summary of the information values.</p>
<pre class="r"><code># Create a WOE table
IV &lt;- create_infotables(data=creditdata_base,
                        y=&quot;default&quot;)
# Print the summary of the IV table information values. Thes IVs are derived from the WOE.
IV$Summary %&gt;% 
      knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th></th>
<th align="left">Variable</th>
<th align="right">IV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td align="left">checkingstatus1</td>
<td align="right">0.6660115</td>
</tr>
<tr class="even">
<td>3</td>
<td align="left">history</td>
<td align="right">0.2932335</td>
</tr>
<tr class="odd">
<td>2</td>
<td align="left">duration</td>
<td align="right">0.2778772</td>
</tr>
<tr class="even">
<td>6</td>
<td align="left">savings</td>
<td align="right">0.1960096</td>
</tr>
<tr class="odd">
<td>4</td>
<td align="left">purpose</td>
<td align="right">0.1691951</td>
</tr>
<tr class="even">
<td>13</td>
<td align="left">age</td>
<td align="right">0.1212277</td>
</tr>
<tr class="odd">
<td>12</td>
<td align="left">property</td>
<td align="right">0.1126383</td>
</tr>
<tr class="even">
<td>5</td>
<td align="left">amount</td>
<td align="right">0.1117618</td>
</tr>
<tr class="odd">
<td>7</td>
<td align="left">employ</td>
<td align="right">0.0864336</td>
</tr>
<tr class="even">
<td>15</td>
<td align="left">housing</td>
<td align="right">0.0832934</td>
</tr>
<tr class="odd">
<td>14</td>
<td align="left">otherplans</td>
<td align="right">0.0576145</td>
</tr>
<tr class="even">
<td>20</td>
<td align="left">foreign</td>
<td align="right">0.0438774</td>
</tr>
<tr class="odd">
<td>9</td>
<td align="left">status</td>
<td align="right">0.0333416</td>
</tr>
<tr class="even">
<td>10</td>
<td align="left">others</td>
<td align="right">0.0320193</td>
</tr>
<tr class="odd">
<td>8</td>
<td align="left">installment</td>
<td align="right">0.0263221</td>
</tr>
<tr class="even">
<td>16</td>
<td align="left">cards</td>
<td align="right">0.0132665</td>
</tr>
<tr class="odd">
<td>17</td>
<td align="left">job</td>
<td align="right">0.0087628</td>
</tr>
<tr class="even">
<td>19</td>
<td align="left">tele</td>
<td align="right">0.0063776</td>
</tr>
<tr class="odd">
<td>11</td>
<td align="left">residence</td>
<td align="right">0.0035888</td>
</tr>
<tr class="even">
<td>18</td>
<td align="left">liable</td>
<td align="right">0.0000434</td>
</tr>
</tbody>
</table>
<p>We will fit another logistic model on the training set. This model will filter variables and create WOE bins using the <a href="https://cran.r-project.org/web/packages/scorecard/index.html">scorecard</a> R package.</p>
<pre class="r"><code># Filter out variables via missing rate, information value, identical value rate
creditdata_filt &lt;- var_filter(creditdata_base, y=&quot;default&quot;)
# Print the remaining number variables of the filtered dataset
dim(creditdata_filt)[2]</code></pre>
<pre><code>## [1] 15</code></pre>
<pre class="r"><code># Weight of average (WOE) binning 
bins &lt;- woebin(creditdata_filt, y=&quot;default&quot;)</code></pre>
<pre><code>## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already
## exporting variable(s): dt, xs, y, breaks_list, min_perc_fine_bin,
## stop_limit, max_num_bin</code></pre>
<pre><code>## Binning on 1000 rows and 15 columns in  0: 0:13</code></pre>
<pre class="r"><code># Let&#39;s visualise the bins created for the numeric variables age, duration and amount
woebin_plot(bins$age)</code></pre>
<pre><code>## $age</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/logistic%20model%202-1.png" width="672" /></p>
<pre class="r"><code>woebin_plot(bins$duration)</code></pre>
<pre><code>## $duration</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/logistic%20model%202-2.png" width="672" /></p>
<pre class="r"><code>woebin_plot(bins$amount)</code></pre>
<pre><code>## $amount</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/logistic%20model%202-3.png" width="672" /></p>
<pre class="r"><code># Let&#39;s visualise the bins created for a categorical variable checkingstatus1 
woebin_plot(bins$checkingstatus1)</code></pre>
<pre><code>## $checkingstatus1</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/logistic%20model%202-4.png" width="672" /></p>
<p>The WOE bin has grouped the <code>age</code> similarly to the coarse bins up until 35 where it has added a group for 35:37. The <code>duration</code> WOE bin grouped by 8 months rather than 12 months until 36 months. For <code>amount</code> there are 5 WOE bins as opposed to 3 bins. For <code>checkingstatus1</code>, the WOE binned less than 0 and 0 to 200DM levels.</p>
<p>The bad probability lines for the age and amount appear contrary to our density plots where it appeared that higher amount is riskier and lower age is riskier.</p>
<pre class="r"><code># Convert train and test sets original input data to WOE values based on WOE binning 
training_woe &lt;- woebin_ply(training_base, bins)</code></pre>
<pre><code>## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already
## exporting variable(s): dt, xs</code></pre>
<pre class="r"><code>test_woe &lt;- woebin_ply(test_base, bins)</code></pre>
<pre><code>## Warning in e$fun(obj, substitute(ex), parent.frame(), e$data): already
## exporting variable(s): dt, xs</code></pre>
<pre class="r"><code># Fit a logistic model 
glm_model2 &lt;- glm(default ~ ., family = &quot;binomial&quot;, data = training_woe)</code></pre>
<pre class="r"><code>prediction_prob2 &lt;- predict(glm_model2, newdata = test_woe, type = &quot;response&quot;)
# Calculate the ROC
ROC_2 &lt;- pROC::roc(test_woe$default,prediction_prob2)
# AUC for fourth model
AUC2 &lt;- auc(ROC_2)
AUC2</code></pre>
<pre><code>## Area under the curve: 0.7951</code></pre>
<pre class="r"><code># KS for fourth model
prediction_2 &lt;- ROCR::prediction(prediction_prob2,test_woe$default)
perf_2 &lt;- ROCR::performance(prediction_2,&quot;tpr&quot;,&quot;fpr&quot;)
KS2 &lt;- max(attr(perf_2,&#39;y.values&#39;)[[1]]-attr(perf_2,&#39;x.values&#39;)[[1]])
KS2</code></pre>
<pre><code>## [1] 0.4846106</code></pre>
<pre class="r"><code># Performance of the WOE model
test_perf &lt;- perf_eva(test_woe$default, prediction_prob2, title = &quot;Model 2&quot;)</code></pre>
<p><img src="https://kimnewzealand.github.io/post/CreditScoreExample_files/figure-html/perf%20model%202-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="create-scorecard" class="section level2">
<h2>Create Scorecard</h2>
<p>Now create a scorecard on the Model 2 using the scorecard package.</p>
<pre class="r"><code># Calculate score card
card &lt;- scorecard(bins, glm_model2)
# Take a look at the scorecard for duration, which includes scorecard points
card$duration %&gt;% 
      knitr::kable()</code></pre>
<table>
<thead>
<tr class="header">
<th align="left">variable</th>
<th align="left">bin</th>
<th align="right">count</th>
<th align="right">count_distr</th>
<th align="right">good</th>
<th align="right">bad</th>
<th align="right">badprob</th>
<th align="right">woe</th>
<th align="right">bin_iv</th>
<th align="right">total_iv</th>
<th align="left">breaks</th>
<th align="left">is_special_values</th>
<th align="right">points</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">duration</td>
<td align="left">[-Inf,8)</td>
<td align="right">87</td>
<td align="right">0.087</td>
<td align="right">78</td>
<td align="right">9</td>
<td align="right">0.1034483</td>
<td align="right">-1.3121864</td>
<td align="right">0.1068495</td>
<td align="right">0.2826181</td>
<td align="left">8</td>
<td align="left">FALSE</td>
<td align="right">66</td>
</tr>
<tr class="even">
<td align="left">duration</td>
<td align="left">[8,16)</td>
<td align="right">344</td>
<td align="right">0.344</td>
<td align="right">264</td>
<td align="right">80</td>
<td align="right">0.2325581</td>
<td align="right">-0.3466246</td>
<td align="right">0.0382938</td>
<td align="right">0.2826181</td>
<td align="left">16</td>
<td align="left">FALSE</td>
<td align="right">18</td>
</tr>
<tr class="odd">
<td align="left">duration</td>
<td align="left">[16,36)</td>
<td align="right">399</td>
<td align="right">0.399</td>
<td align="right">270</td>
<td align="right">129</td>
<td align="right">0.3233083</td>
<td align="right">0.1086883</td>
<td align="right">0.0048133</td>
<td align="right">0.2826181</td>
<td align="left">36</td>
<td align="left">FALSE</td>
<td align="right">-6</td>
</tr>
<tr class="even">
<td align="left">duration</td>
<td align="left">[36,44)</td>
<td align="right">100</td>
<td align="right">0.100</td>
<td align="right">58</td>
<td align="right">42</td>
<td align="right">0.4200000</td>
<td align="right">0.5245245</td>
<td align="right">0.0299728</td>
<td align="right">0.2826181</td>
<td align="left">44</td>
<td align="left">FALSE</td>
<td align="right">-27</td>
</tr>
<tr class="odd">
<td align="left">duration</td>
<td align="left">[44, Inf)</td>
<td align="right">70</td>
<td align="right">0.070</td>
<td align="right">30</td>
<td align="right">40</td>
<td align="right">0.5714286</td>
<td align="right">1.1349799</td>
<td align="right">0.1026887</td>
<td align="right">0.2826181</td>
<td align="left">Inf</td>
<td align="left">FALSE</td>
<td align="right">-57</td>
</tr>
</tbody>
</table>
<p>This scorecards calculate points based on the probabilities, WOE and IV. We observed in the EDA that the bad outcomes increased with duration. In the scorecard higher points are awarded for lower durations, which is indicates a similar relationship.</p>
</div>
<div id="conclusions" class="section level2">
<h2>Conclusions</h2>
<p>This dataset has no missing variables, no outliers and is not a heavily imbalanced dataset so we have not had to overcome these real world challenges in this exercise. However the imbalance and size of dataset is not representative of real world data. Other data such as credit bureau and time series data could be used in addition to approved loans data in practice.</p>
<p>When we compare each of the models, with different manual and optimised binning methods, the AUCs for the two models are as follows:</p>
<pre class="r"><code># Model 1 - Logistic Model with Coarse Binning
AUC</code></pre>
<pre><code>## Area under the curve: 0.7804</code></pre>
<pre class="r"><code># Model 2 - Logistic Model with WOE Binning
AUC2</code></pre>
<pre><code>## Area under the curve: 0.7951</code></pre>
<p>Model 2 with the WOE binning has the higher AUC.</p>
<p>Finally, this very simple model using the glm function is one model option for credit risk modeling. In a real life application, other algorithms and packages would be used as baseline and for comparison in building models for implementation.</p>
<div id="acknowledgements" class="section level3">
<h3>Acknowledgements</h3>
<ul>
<li>DataCamp <a href="https://campus.datacamp.com/courses/introduction-to-credit-risk-modeling-in-r/">Introduction to Credit Modeling course in R</a><br />
</li>
<li><a href="https://www.smartcat.io/blog/2017/woe-and-iv-variable-screening-with-information-in-r/">WoE and IV Variable Screening with {Information} in R</a></li>
<li><a href="https://cran.r-project.org/doc/contrib/Sharma-CreditScoring.pdf">Sharma CreditScoring</a></li>
<li><a href="https://twitter.com/ross_gayler?lang=en">Ross Gayler</a> for review and discussion on credit risk modeling in practice.</li>
</ul>
</div>
</div>


  
<div class="prev-next-post pure-g">
  <div class="pure-u-1-24" style="text-align: left;">
    
    <a href="https://kimnewzealand.github.io/2018/07/19/excel-r-tutorial/"><i class="fa fa-chevron-left"></i></a>
    
  </div>
  <div class="pure-u-10-24">
    
    <nav class="prev">
      <a href="https://kimnewzealand.github.io/2018/07/19/excel-r-tutorial/">Tutorial on Pivot Tables and other Excel things you can also do in R - Witch Trials data</a>
    </nav>
    
  </div>
  <div class="pure-u-2-24">
    &nbsp;
  </div>
  <div class="pure-u-10-24">
    
    <nav class="next">
      <a href="https://kimnewzealand.github.io/2018/08/15/changing-theme-with-blogdown/">Changing Theme with Blogdown</a>
    </nav>
    
  </div>
  <div class="pure-u-1-24" style="text-align: right;">
    
    <a href="https://kimnewzealand.github.io/2018/08/15/changing-theme-with-blogdown/"><i class="fa fa-chevron-right"></i></a>
    
  </div>
</div>



  

</div>

</div>
</div>
<script src="https://kimnewzealand.github.io/js/ui.js"></script>


<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-114904130-1', 'auto');
  ga('send', 'pageview');

</script>





</body>
</html>

